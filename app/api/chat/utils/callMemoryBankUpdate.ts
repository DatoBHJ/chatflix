/**
 * Utility function for making API calls to AI providers for memory bank updates
 */

/**
 * í´ë°± ë©”ëª¨ë¦¬ ì»¨í…ì¸  ìƒì„± (OpenAI API ì‚¬ìš© ë¶ˆê°€ì‹œ)
 */
function generateFallbackMemoryContent(systemPrompt: string, userPrompt: string): string {
  const currentDate = new Date().toLocaleDateString();
  
  // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì—ì„œ ë©”ëª¨ë¦¬ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì‹œë„
  let category = 'general';
  if (systemPrompt.includes('personal information') || userPrompt.includes('personal')) {
    category = 'personal-info';
  } else if (systemPrompt.includes('preferences')) {
    category = 'preferences';
  } else if (systemPrompt.includes('interests')) {
    category = 'interests';
  } else if (systemPrompt.includes('interaction') || systemPrompt.includes('history')) {
    category = 'interaction-history';
  } else if (systemPrompt.includes('relationship')) {
    category = 'relationship';
  }
  
  return `# ${category.charAt(0).toUpperCase() + category.slice(1)} (Fallback Mode)

âš ï¸ **Note**: This memory entry was created in fallback mode due to AI service unavailability.

## Last Updated
${currentDate}

## Status
Memory update temporarily unavailable - AI analysis service offline.
Basic structure maintained for future updates.

## Notes
- Full analysis will be performed when AI service is restored
- User activity continues to be tracked
- This placeholder ensures memory structure consistency
`;
}

/**
 * Makes a call to the OpenAI API with the given prompts to update user memory
 * 
 * @param model - The model to use (e.g., 'gpt-4.1-nano')
 * @param systemPrompt - The system prompt for context
 * @param userPrompt - The user prompt with the actual query
 * @param maxTokens - Maximum tokens to generate (default: 500)
 * @param temperature - Temperature for generation (default: 0.3)
 * @returns The generated content or null if the request fails
 */
export async function callMemoryBankUpdate(
  model: string, 
  systemPrompt: string, 
  userPrompt: string, 
  maxTokens: number = 500, 
  temperature: number = 0.3
): Promise<string | null> {
  try {
    console.log(`ğŸ¤– [MEMORY AI] Calling OpenAI API with model: ${model}`);
    
    // Check if API key exists
    if (!process.env.OPENAI_API_KEY) {
      console.error("âŒ [MEMORY AI] Missing OPENAI_API_KEY environment variable - memory update skipped");
      
      // ğŸ†• ê°„ë‹¨í•œ í´ë°± ë©”ì»¤ë‹ˆì¦˜ ì œê³µ
      return generateFallbackMemoryContent(systemPrompt, userPrompt);
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        max_tokens: maxTokens,
        temperature: temperature
      })
    });
    
    if (!response.ok) {
      const errorData = await response.text();
      console.error(`âŒ [MEMORY AI] API call failed with status ${response.status}: ${errorData}`);
      
      // ğŸ†• íŠ¹ì • ì—ëŸ¬ ì½”ë“œì— ëŒ€í•œ í´ë°± ì œê³µ
      if (response.status === 429 || response.status >= 500) {
        console.log(`ğŸ”„ [MEMORY AI] Providing fallback content due to API issues`);
        return generateFallbackMemoryContent(systemPrompt, userPrompt);
      }
      
      return null;
    }
    
    const data = await response.json();
    const content = data.choices?.[0]?.message?.content || '';
    
    if (content) {
      console.log(`âœ… [MEMORY AI] Successfully generated memory content (${content.length} chars)`);
    } else {
      console.error(`âŒ [MEMORY AI] No content received from OpenAI API`);
    }
    
    return content;
  } catch (error) {
    console.error("âŒ [MEMORY AI] Error calling memory bank update API:", error);
    return null;
  }
} 

import { streamText, createUIMessageStream, createUIMessageStreamResponse, streamObject, generateObject, UIMessage, type ModelMessage, stepCountIs, convertToModelMessages, smoothStream, NoSuchToolError } from 'ai';
import { createClient } from '@/utils/supabase/server';
import { providers } from '@/lib/providers';
import { getModelById} from '@/lib/models/config';
// AI SDK v5 ë„¤ì´í‹°ë¸Œ íƒ€ì…ë§Œ ì‚¬ìš©
// import { z } from 'zod';
import { 
  
  // saveUserMessage,
  // createOrUpdateAssistantMessage,
  // handleStreamCompletion,
  saveCompletedMessages,
  buildSystemPrompt,
  getCachedUserMemory
} from './services/chatService';
import { 
  generateMessageId, 
  validateAndUpdateSession,
  getProviderFromModel,
  // convertMultiModalToMessage,
  // selectMessagesWithinTokenLimit,
  // detectImages,
  // detectPDFs,
  // detectCodeAttachments,
  // fetchFileContent,
  extractTextFromMessage,
  extractTextFromCompletion,
  generateFollowUpQuestions,
  processMessagesForAI
} from './utils/messageUtils';
import { 
  TOOL_REGISTRY,
  // initializeTool,
  getAvailableTools,
  getToolDescriptions,
  collectToolResults
} from './utils/toolUtils';
import { handleRateLimiting, handleChatflixRateLimiting } from './utils/ratelimit';
// import { toolPrompts } from './prompts/toolPrompts';
import { checkSubscriptionFromDatabase } from '@/lib/subscription-db';
import { getProviderOptionsWithTools } from './utils/providerOptions';

// ë¹„êµ¬ë…ì ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì œí•œ ì œê±°ë¨

// ë©”ëª¨ë¦¬ ê´€ë ¨ import
import { initializeMemoryBank, getAllMemoryBank, getUserPersonalInfo } from '@/utils/memory-bank';
import { smartUpdateMemoryBanks } from './services/memoryService';
import { estimateTokenCount } from '@/utils/context-manager';
import { selectOptimalModel } from './services/modelSelector';
import { estimateMultiModalTokens } from '@/utils/context-manager';
// import { 
//   analyzeRequestAndDetermineRoute
// } from './services/analysisService';
// import { markdownJoinerTransform } from './markdown-transform';

// ğŸš€ ìµëª… ì‚¬ìš©ììš© UUID ìƒì„± í•¨ìˆ˜
function generateAnonymousUserId(): string {
  // UUID v4 í˜•ì‹ìœ¼ë¡œ ìµëª… ì‚¬ìš©ì ID ìƒì„±
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
    const r = Math.random() * 16 | 0;
    const v = c === 'x' ? r : (r & 0x3 | 0x8);
    return v.toString(16);
  });
}

// Helper function to increment user daily request count
async function incrementSuccessfulRequestCount(
  supabaseClient: any,
  userId: string,
  requestDate: string,
  currentCount: number,
  isUserSubscribed: boolean
) {
  try {
    await supabaseClient
      .from('user_daily_requests')
      .upsert({
        user_id: userId,
        date: requestDate,
        count: currentCount + 1,
        last_request_at: new Date().toISOString(),
        is_subscribed: isUserSubscribed
      }, {
        onConflict: 'user_id,date' 
      });
  } catch (error) {
    // console.error('Failed to update successful request count:', error);
  }
}


export async function POST(req: Request): Promise<Response> {
  const supabase = await createClient();
  const { data: { user }, error: userError } = await supabase.auth.getUser();
  
  // ğŸš€ ìµëª… ì‚¬ìš©ì ì§€ì›: ë¡œê·¸ì¸í•˜ì§€ ì•Šì€ ì‚¬ìš©ìë„ ê¸°ë³¸ ì±„íŒ… ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥
  if (userError) {
    // AuthSessionMissingError(400)ì€ ìµëª… ì‹œ ì •ìƒ ë™ì‘ì´ë¯€ë¡œ ë¡œê¹…í•˜ì§€ ì•ŠìŒ
    const status = (userError as any)?.status;
    if (status && status !== 400) {
      console.error('Auth error:', userError);
    }
    // ìµëª… ì‚¬ìš©ìë¡œ ì²˜ë¦¬ ê³„ì† ì§„í–‰
  }
  
  // ìµëª… ì‚¬ìš©ì í—¤ë” í™•ì¸
  const isAnonymousUser = !user;
  const anonymousUserId = req.headers.get('X-Anonymous-Id') || generateAnonymousUserId();

  const requestData = await req.json();
  
  // Track client aborts and wire to internal streams
  let abortedByClient = false;
  let internalAbortController: AbortController | null = null;
  try {
    // In Next.js/Fetch, Request has an AbortSignal
    const reqSignal: any = (req as any).signal;
    if (reqSignal && typeof reqSignal.addEventListener === 'function') {
      reqSignal.addEventListener('abort', () => {
        abortedByClient = true;
        try { internalAbortController?.abort(); } catch {}
      });
    }
  } catch {}
  let { messages, model, chatId, isRegeneration, existingMessageId, saveToDb = true, isAgentEnabled = false, selectedTool, experimental_attachments } = requestData;
  
  // ğŸš€ chatId ê²€ì¦ ë° ì •ë¦¬
  if (!chatId || typeof chatId !== 'string' || chatId.trim() === '') {
    console.error('ğŸ’¥ [CHAT] Invalid chatId:', chatId);
    return new Response('Invalid chatId', { status: 400 });
  }
  chatId = chatId.trim();
  console.log('ğŸ” [CHAT] Processing chatId:', chatId);
  
  // ğŸš€ ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬: ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ì— experimental_attachments ì¶”ê°€
  if (experimental_attachments && experimental_attachments.length > 0 && messages.length > 0) {
    const lastUserMessage = messages[messages.length - 1];
    if (lastUserMessage.role === 'user') {
      lastUserMessage.experimental_attachments = experimental_attachments;
    }
  }
  
  // ğŸš€ ìµëª… ì‚¬ìš©ì ì§€ì›: ì¼ë‹¨ ëª¨ë“  ê¸°ëŠ¥ í—ˆìš© (ë‚˜ì¤‘ì— ì œí•œ ì¶”ê°€ ì˜ˆì •)
  // if (isAnonymousUser) {
  //   // ìµëª… ì‚¬ìš©ìëŠ” ê¸°ë³¸ ëª¨ë¸ë§Œ ì‚¬ìš© ê°€ëŠ¥
  //   const allowedModels = ['gpt-4o-mini', 'gemini-2.0-flash-exp', 'claude-3-5-sonnet'];
  //   if (!allowedModels.includes(model)) {
  //     model = 'gpt-4o-mini'; // ê¸°ë³¸ ëª¨ë¸ë¡œ ë³€ê²½
  //   }
  //   
  //   // ìµëª… ì‚¬ìš©ìëŠ” ì—ì´ì „íŠ¸ ëª¨ë“œ ë¹„í™œì„±í™”
  //   isAgentEnabled = false;
  //   selectedTool = null;
  //   
  //   // ìµëª… ì‚¬ìš©ìëŠ” DB ì €ì¥í•˜ì§€ ì•ŠìŒ
  //   saveToDb = false;
  // }
  
  // ì›ë³¸ ë©”ì‹œì§€ ë°°ì—´ ë³´ì¡´ (ëª¨ë“  ìŠ¤ì½”í”„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
  const originalMessages = messages.slice();

  // Map Chatflix Ultimate model to appropriate model based on agent mode
  if (model === 'chatflix-ultimate' || model === 'chatflix-ultimate-pro') {
      // Store the original model name for DB storage
      requestData.originalModel = model;
      
      try {
        const modelType = model as 'chatflix-ultimate' | 'chatflix-ultimate-pro';
        const { selectedModel } = await selectOptimalModel(messages, modelType);
        model = selectedModel;
      } catch (error) {
        model = 'gemini-2.5-pro';
      }
    }

  // êµ¬ë… ìƒíƒœ í™•ì¸ (ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜) - ìµëª… ì‚¬ìš©ìëŠ” ë°”ë¡œ falseë¡œ ì²˜ë¦¬í•˜ì—¬ ë¶ˆí•„ìš”í•œ DB/Polar/Redis í˜¸ì¶œ ì œê±°
  const isSubscribed = isAnonymousUser
    ? false
    : await checkSubscriptionFromDatabase(user!.id);
  
  // ëª¨ë¸ì´ ë°”ë€ í›„ ìµœì¢… ëª¨ë¸ ì„¤ì •ìœ¼ë¡œ maxContextTokens ì¬ê³„ì‚°
  const finalModelConfig = getModelById(model);
  const maxContextTokens = finalModelConfig?.contextWindow || 120000;
  
  // ì‚¬ìš©ìì˜ ì˜¤ëŠ˜ ìš”ì²­ íšŸìˆ˜ í™•ì¸
  const today = new Date().toISOString().split('T')[0]; // YYYY-MM-DD í˜•ì‹
  const { data: userRequests, error: requestsError } = await supabase
    .from('user_daily_requests')
    .select('count')
    .eq('user_id', user?.id || anonymousUserId)
    .eq('date', today)
    .single();
  
  // í˜„ì¬ ìš”ì²­ íšŸìˆ˜ (ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì‹œì‘)
  const currentRequestCount = userRequests?.count || 0;

  // ğŸ†• Handle rate limiting based on model type
  const originalModel = requestData.originalModel;
  const isChatflixModel = originalModel === 'chatflix-ultimate' || originalModel === 'chatflix-ultimate-pro';
  
  // ğŸš€ ìµëª… ì‚¬ìš©ì rate limit: ì¼ë‹¨ ì¼ë°˜ ì‚¬ìš©ìì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
  // if (isAnonymousUser) {
  //   // ìµëª… ì‚¬ìš©ìëŠ” ë” ì—„ê²©í•œ rate limit ì ìš© (êµ¬ë…í•˜ì§€ ì•Šì€ ì‚¬ìš©ìë¡œ ì²˜ë¦¬)
  //   const anonymousRateLimitResult = await handleRateLimiting(anonymousUserId, model, false);
  //   if (!anonymousRateLimitResult.success) {
  //     const { error } = anonymousRateLimitResult;
  //     return new Response(JSON.stringify(error), {
  //       status: 429,
  //       headers: { 'Content-Type': 'application/json' }
  //     });
  //   }
  // } else 
  if (isChatflixModel) {
    // Chatflix ëª¨ë¸ì€ ìì²´ rate limitë§Œ ì²´í¬ (ì„ íƒëœ ê°œë³„ ëª¨ë¸ rate limit ë¬´ì‹œ)
    const chatflixRateLimitResult = await handleChatflixRateLimiting(user?.id || anonymousUserId, originalModel, isSubscribed);
    if (!chatflixRateLimitResult.success) {
      const { error } = chatflixRateLimitResult;
      
      if (error) {
        return new Response(JSON.stringify({
          error: 'Too many requests',
          message: error.message,
          retryAfter: error.retryAfter,
          reset: new Date(error.reset).toISOString(),
          limit: error.limit,
          level: error.level,
          model: originalModel, // Use original Chatflix model name
          isSubscribed: isSubscribed // êµ¬ë… ìƒíƒœ í¬í•¨
        }), {
          status: 429,
          headers: {
            'Content-Type': 'application/json',
            'X-RateLimit-Limit': error.limit.toString(),
            'X-RateLimit-Remaining': '0',
            'X-RateLimit-Reset': new Date(error.reset).toISOString(),
          }
        });
      }
    }
  } else {
    // ì¼ë°˜ ëª¨ë¸ì€ ê¸°ì¡´ ë¡œì§ ì‚¬ìš© (ìµëª… ì‚¬ìš©ìëŠ” rate limit ì²´í¬ ê±´ë„ˆë›°ê¸°)
    if (!isAnonymousUser) {
      const rateLimitResult = await handleRateLimiting(user?.id || anonymousUserId, model, isSubscribed);
      if (!rateLimitResult.success) {
        const { error } = rateLimitResult;
        
        if (error) {
          return new Response(JSON.stringify({
            error: 'Too many requests',
            message: error.message,
            retryAfter: error.retryAfter,
            reset: new Date(error.reset).toISOString(),
            limit: error.limit,
            level: error.level,
            model: model,
            isSubscribed: isSubscribed // êµ¬ë… ìƒíƒœ í¬í•¨
          }), {
            status: 429,
            headers: {
              'Content-Type': 'application/json',
              'X-RateLimit-Limit': error.limit.toString(),
              'X-RateLimit-Remaining': '0',
              'X-RateLimit-Reset': new Date(error.reset).toISOString(),
            }
          });
        } else {
          // Fallback in case error is undefined
          return new Response(JSON.stringify({
            error: 'Too many requests',
            message: 'Rate limit exceeded',
            isSubscribed: isSubscribed // êµ¬ë… ìƒíƒœ í¬í•¨
          }), {
            status: 429,
            headers: {
              'Content-Type': 'application/json'
            }
          });
        }
      }
    }
  }

  let globalCollectedToolResults: any = {}; // Store tool results globally
  
  const stream = createUIMessageStream({
    originalMessages: messages,
    execute: async ({ writer }): Promise<void> => {
        // ğŸš€ AI ì‘ë‹µ ì¦‰ì‹œ ì‹œì‘ (ì„¸ì…˜ ì²˜ë¦¬ì™€ ì™„ì „ ë¶„ë¦¬)
        const processMessages = [...messages];

        // v5 pattern: do not persist user/assistant mid-stream; save at onFinish only
        const assistantMessageId = isRegeneration && existingMessageId 
          ? existingMessageId 
          : generateMessageId();

        // Expose for onError/onFinish handlers
        // assistantMessageIdGlobal = assistantMessageId;

        const abortController = new AbortController();
        // expose the internal controller for client abort wiring
        internalAbortController = abortController;

        // Add abort handler to prevent message saving when stream is stopped
        let abortSavePromise: Promise<void> | null = null;
        abortController.signal.addEventListener('abort', () => {
          console.log('ğŸ›‘ [ABORT] Stream aborted, but will save partial response');
          
          // ğŸš€ ì¤‘ë‹¨ ì‹œì—ë„ ë¶€ë¶„ ì €ì¥ í—ˆìš© (abortedByClient = false ìœ ì§€)
          // abortedByClient = true; // ì´ ì¤„ ì œê±°
          
          // Prevent multiple abort saves
          if (abortSavePromise) return;
          
          abortSavePromise = (async () => {
            try {
              // Give a small delay for any in-flight UI updates
              await new Promise(resolve => setTimeout(resolve, 100));
              
              console.log('ğŸ›‘ [ABORT] Server-side abort completed, partial save will be attempted');
            } catch (error) {
              console.error('ğŸ›‘ [ABORT] Failed to handle abort:', error);
            }
          })();
        });

        const modelConfig = getModelById(model);

        // 3. í–¥ìƒëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìºì‹œëœ ë©”ëª¨ë¦¬ ì‚¬ìš©) - ì—ëŸ¬ ì‹œì—ë„ ê³„ì† ì§„í–‰
        let userMemory = null;
        try {
          userMemory = !isAnonymousUser ? await getCachedUserMemory(user?.id || anonymousUserId) : null;
        } catch (memoryError) {
          console.error('ğŸ§  [MEMORY] Failed to load user memory, continuing without it:', memoryError);
          userMemory = null;
        }
        const currentSystemPrompt = buildSystemPrompt(
          isAgentEnabled ? 'agent' : 'regular',
          userMemory
        );
        
        // ğŸ”§ MEDIUM PRIORITY OPTIMIZATION: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í† í° ê³„ì‚° í•œ ë²ˆë§Œ ìˆ˜í–‰
        const systemTokensCounts = estimateTokenCount(currentSystemPrompt);
        // ì´ë¯¸ ìœ„ì—ì„œ ê³„ì‚°ëœ maxContextTokens ì‚¬ìš©
        let remainingTokens = maxContextTokens - systemTokensCounts;
        
        // ğŸ”§ MEDIUM PRIORITY OPTIMIZATION: ë©”ì‹œì§€ë³„ í† í° ë¯¸ë¦¬ ê³„ì‚° ë° ìºì‹±
        const messagesWithTokens = processMessages.map(msg => {
          const tokenCount = estimateMultiModalTokens(msg as any);
          return {
            ...msg,
            _tokenCount: tokenCount
          };
        });
        
        if (isAgentEnabled) {
          
          // Re-calculate system tokens specifically for agent mode for accuracy
          const agentSystemPromptForCalc = buildSystemPrompt('agent', userMemory);
          
          const agentSystemTokens = estimateTokenCount(agentSystemPromptForCalc);
          remainingTokens = maxContextTokens - agentSystemTokens;

          const optimizedMessagesForRouting = messagesWithTokens;

          // í˜„ì¬ ì§ˆë¬¸ ì¶”ì¶œì„ ìœ„í•œ ì¤€ë¹„
          let userQuery = '';
          
          // í˜„ì¬ ì§ˆë¬¸ë§Œ userQueryì— í• ë‹¹
          const currentMessage = optimizedMessagesForRouting[optimizedMessagesForRouting.length - 1];
          userQuery = extractTextFromMessage(currentMessage);

                     // ğŸ†• STEP 0: Request Routing Analysis


          // ğŸ†• ì‚¬ìš©ìê°€ ì§ì ‘ ë„êµ¬ë¥¼ ì„ íƒí•œ ê²½ìš° vs ìë™ ë¼ìš°íŒ…
          let selectedActiveTools: Array<keyof typeof TOOL_REGISTRY>;
          
          // ğŸ”§ FIX: ì¤‘ë³µ ì œê±° í—¬í¼ í•¨ìˆ˜
          const addToolsWithPreviousResults = (tools: string[]): Array<keyof typeof TOOL_REGISTRY> => {
            const toolsWithoutPrevious = tools.filter(tool => tool !== 'previous_tool_results');
            const finalTools = ['previous_tool_results', ...toolsWithoutPrevious] as Array<keyof typeof TOOL_REGISTRY>;
            
            // ì¤‘ë³µ ì œê±° ë¡œê·¸
            if (tools.includes('previous_tool_results')) {
              console.log(`[TOOL_SELECTION] Removed duplicate previous_tool_results from: [${tools.join(', ')}] -> [${finalTools.join(', ')}]`);
            }
            
            return finalTools;
          };
          
          if (selectedTool && selectedTool !== 'file_upload') {
            // ì‚¬ìš©ìê°€ ì§ì ‘ ë„êµ¬ë¥¼ ì„ íƒí•œ ê²½ìš°
            console.log(`[TOOL_SELECTION] User selected tool: ${selectedTool}`);
            
            // ì›¹ì„œì¹˜ í† í”½ì¸ ê²½ìš° ì²˜ë¦¬
            if (selectedTool.startsWith('web_search:')) {
              const topic = selectedTool.split(':')[1];
              console.log(`[TOOL_SELECTION] Web search with specific topic: ${topic}`);
              
              // ì›¹ì„œì¹˜ ë„êµ¬ì— íŠ¹ì • í† í”½ì„ ê°•ì œë¡œ ì„¤ì •
              selectedActiveTools = addToolsWithPreviousResults(['web_search']);
              
              // ì›¹ì„œì¹˜ ë„êµ¬ ìƒì„± ì‹œ ì‚¬ìš©í•  í† í”½ ì •ë³´ë¥¼ ì €ì¥
              (writer as any)._selectedWebSearchTopic = topic;
            } else {
              // ì¼ë°˜ ë„êµ¬ì¸ ê²½ìš°
              selectedActiveTools = addToolsWithPreviousResults([selectedTool]);
            }
          } else {
            // ğŸš€ ëª¨ë“  ë„êµ¬ í—ˆìš© (ë¼ìš°íŒ… ë¶„ì„ ìƒëµ)
            console.log(`[TOOL_SELECTION] Using all available tools (routing analysis skipped)`);
            const allAvailableTools = getAvailableTools();
            selectedActiveTools = addToolsWithPreviousResults(allAvailableTools);
            
            // ğŸ”§ ê¸°ì¡´ ë¼ìš°íŒ… ë¶„ì„ ì½”ë“œ (ì£¼ì„ ì²˜ë¦¬ - í•„ìš”ì‹œ ë³µì› ê°€ëŠ¥)
            /*
            // ìë™ ë¼ìš°íŒ… ì‚¬ìš©
            console.log(`[TOOL_SELECTION] Using automatic routing`);
            const baseAvailableToolsList = getAvailableTools();
            const analysisModel = 'gemini-2.0-flash';
            const toolDescriptions = getToolDescriptions();

            // ğŸš€ V6 Plan: New unified analysis and routing
            // ğŸ”§ FIX: Use unified converter for analysis
            const messagesForAnalysis = convertToModelMessages(messagesWithTokens);

            const routeAnalysisResult = await analyzeRequestAndDetermineRoute(
              analysisModel,
              model,
              baseAvailableToolsList,
              messagesForAnalysis, // Use converted messages for routing analysis
              toolDescriptions
            );
            
            const routingDecision = routeAnalysisResult.object;
            selectedActiveTools = addToolsWithPreviousResults(routingDecision.tools);
            */
          }
              
          // ğŸ†• AI SDK v5: ì „ì²´ ë„êµ¬ ì„¸íŠ¸ ì •ì˜ + í™œì„± ë„êµ¬ ì œí•œ
          const allTools = Object.fromEntries(
            Object.entries(TOOL_REGISTRY).map(([toolName, config]) => [
              toolName,
              toolName === 'previous_tool_results' 
                ? (config.createFn as any)(writer, chatId) // previous_tool_resultsì—ë§Œ chatId ì „ë‹¬
                : toolName === 'web_search' && (writer as any)._selectedWebSearchTopic
                ? config.createFn(writer, (writer as any)._selectedWebSearchTopic) // ì›¹ì„œì¹˜ì— ê°•ì œ í† í”½ ì „ë‹¬
                : config.createFn(writer)
            ])
          );
              
              // Provider options with tools
              const providerOptions = getProviderOptionsWithTools(
                model,
                modelConfig,
                user?.id || anonymousUserId,
                selectedActiveTools.length > 0,
                chatId
              );

              // RESPOND: ë„êµ¬ ì‹¤í–‰ ëª¨ë¸ ê²°ì •
              let toolExecutionModel = model;

              // ğŸ†• STEP 2: Prepare optimized messages for final execution
              // ğŸ”§ AI SDK v5: ê³µí†µ ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜ ì‚¬ìš© (ë„êµ¬ ìœ ë¬´ì™€ ê´€ê³„ì—†ì´ ë™ì¼)
              const finalMessagesForExecution = await processMessagesForAI(messagesWithTokens);
              
              // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì • (ìºì‹œëœ ë©”ëª¨ë¦¬ ì‚¬ìš©)
              const systemPrompt = buildSystemPrompt(
                'agent', 
                userMemory,
                {
                  selectedTools: selectedActiveTools
                }
              );

              // ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš° í…ìŠ¤íŠ¸ ì‘ë‹µì„ ì¡°ê±´ë¶€ë¡œ ì²˜ë¦¬
              const textResponsePromise = streamText({
                model: providers.languageModel(toolExecutionModel),
                experimental_transform: [
                  smoothStream({delayInMs: 25}),
                  // markdownJoinerTransform(),
                ],
                system: systemPrompt,
                messages: finalMessagesForExecution,
                tools: allTools,
                activeTools: selectedActiveTools,
                providerOptions,
                // Allow up to 10 tool-using steps; then force a final answer without tools on step 11
                stopWhen: stepCountIs(selectedActiveTools?.length > 0 ? 11 : 3),
                prepareStep: ({ stepNumber }) => {
                  // After 10 steps of potential tool usage, force a text-only answer
                  if (stepNumber > 10) {
                    return {
                      toolChoice: 'none',
                      activeTools: []
                    };
                  }
                  return undefined;
                },
                toolChoice: 'auto',
                maxRetries: 20,
                abortSignal: abortController.signal,
                experimental_repairToolCall: async ({ toolCall, tools, inputSchema, error }) => {
                  if (NoSuchToolError.isInstance(error)) {
                    return null; // do not attempt to fix invalid tool names
                  }

                  console.log('ğŸ”§ [REPAIR] Fixing tool call');
                  console.log('ğŸ”§ [REPAIR] toolCall:', toolCall);
                  console.log('ğŸ”§ [REPAIR] tools:', Object.keys(tools));
                  console.log('ğŸ”§ [REPAIR] parameterSchema:', inputSchema);
                  console.log('ğŸ”§ [REPAIR] error:', error);

                  const tool = tools[toolCall.toolName as keyof typeof tools];

                  // Pre-process the input to handle JSON string cases
                  let processedInput = toolCall.input;
                  if (typeof toolCall.input === 'string') {
                    try {
                      processedInput = JSON.parse(toolCall.input);
                    } catch {
                      // If it's not valid JSON, keep as is
                    }
                  }

                  const { object: repairedArgs } = await generateObject({
                    model: providers.languageModel('moonshotai/kimi-k2-instruct'),
                    schema: tool.inputSchema,
                    prompt: [
                      `The model tried to call the tool "${toolCall.toolName}" with the following arguments:`,
                      JSON.stringify(processedInput),
                      `The tool accepts the following schema:`,
                      JSON.stringify(inputSchema(toolCall)),
                      'Please fix the arguments to match the schema exactly.',
                      'Ensure all required fields are provided and data types are correct.',
                      'If you see JSON strings that should be arrays, parse them properly.',
                      `Today's date is ${new Date().toLocaleDateString('en-US', {
                        year: 'numeric',
                        month: 'long',
                        day: 'numeric',
                      })}`,
                    ].join('\n'),
                  });

                  console.log('ğŸ”§ [REPAIR] repairedArgs:', repairedArgs);

                  return { ...toolCall, args: JSON.stringify(repairedArgs) };
                },
                onChunk: process.env.NODE_ENV === 'development' ? (event) => {
                  const { chunk } = event;
                  if (chunk?.type === 'tool-call' || chunk?.type === 'tool-result') {
                    // ê°œë°œ í™˜ê²½ì—ì„œë§Œ ë„êµ¬ í˜¸ì¶œ ë¡œê¹…
                  }
                } : undefined,
                onFinish: async (completion) => {
                  if (abortController.signal.aborted) return;
                  
                  // ê°„ë‹¨í•œ ë„êµ¬ ê²°ê³¼ ìˆ˜ì§‘ (TOOL_REGISTRY êµ¬ì¡°ì— ë§ê²Œ)
                  const collectedToolResults = collectToolResults(allTools, selectedActiveTools);
                  await incrementSuccessfulRequestCount(supabase, user?.id || anonymousUserId, today, currentRequestCount, isSubscribed);
                  // ğŸš€ Kimi K2 ëª¨ë¸ í˜¸í™˜ì„±: ì•ˆì „í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                  const aiResponse = extractTextFromCompletion(completion);
                  const followUpQuestions = await generateFollowUpQuestions(userQuery, aiResponse);
                  
                  const structuredResponse = {
                    response: { 
                      followup_questions: followUpQuestions 
                    }
                  };
                  collectedToolResults.structuredResponse = structuredResponse;
                  globalCollectedToolResults = { ...collectedToolResults };
                  
                  writer.write({
                    type: 'data-structured_response',
                    id: `structured-${assistantMessageId}`,
                    data: structuredResponse,
                  });
                }
              });

              textResponsePromise.consumeStream();
              writer.merge(textResponsePromise.toUIMessageStream({
                sendReasoning: true,
              }));
        } else {
          // ì¼ë°˜ ì±„íŒ… íë¦„ - ì›ë˜ ì½”ë“œ ì‚¬ìš©ì— í† í° ì œí•œ ìµœì í™” ì¶”ê°€
          //  ì´ë¯¸ ê³„ì‚°ëœ ì‹œìŠ¤í…œ í† í° ì¬ì‚¬ìš©

          // ğŸ”§ AI SDK v5: ê³µí†µ ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜ ì‚¬ìš©
          const messages: ModelMessage[] = await processMessagesForAI(messagesWithTokens);
          
          // Get provider options for regular (non-agent) mode
          const regularProviderOptions = getProviderOptionsWithTools(
            model,
            modelConfig,
            user?.id || anonymousUserId,
            false, // No tools in regular mode
            chatId
          );
          
          const result = streamText({
            model: providers.languageModel(model),
            experimental_transform: [
              smoothStream({delayInMs: 25}),
              // markdownJoinerTransform(),
            ],
            system: currentSystemPrompt,
            messages: messages,
            providerOptions: regularProviderOptions,
            stopWhen: stepCountIs(3),
            maxRetries: 20,
            abortSignal: abortController.signal,
            onFinish: async (completion) => {
              if (abortController.signal.aborted) return;

              // Increment daily request count only on successful, non-aborted completion
              if (!abortController.signal.aborted && !isAnonymousUser) {
                await incrementSuccessfulRequestCount(
                  supabase,
                  user?.id || anonymousUserId,
                  today,
                  currentRequestCount,
                  isSubscribed
                );
              }

              // ğŸš€ ì¼ë°˜ ëª¨ë“œì—ì„œë„ followup questions ìƒì„±
              const currentMessage = messagesWithTokens[messagesWithTokens.length - 1];
              const userQuery = extractTextFromMessage(currentMessage);
              // ğŸš€ Kimi K2 ëª¨ë¸ í˜¸í™˜ì„±: ì•ˆì „í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
              const aiResponse = extractTextFromCompletion(completion);
              const followUpQuestions = await generateFollowUpQuestions(userQuery, aiResponse);
              
              const structuredResponse = {
                response: { 
                  followup_questions: followUpQuestions 
                }
              };
              
              writer.write({
                type: 'data-structured_response',
                id: `structured-${assistantMessageId}`,
                data: structuredResponse,
              });
            }
          });
          writer.merge(result.toUIMessageStream({
            sendReasoning: true,
          }));
    }
    },
    onError: (error) => {
      console.error('ğŸ’¥ [onError]:', error);
      return 'Oops, an error occurred!';
    },
    onFinish: async ({ messages: completedMessages }) => {
      // ğŸš€ ì¤‘ë‹¨ëœ ì‘ë‹µë„ ë¶€ë¶„ ì €ì¥ í—ˆìš© (abortedByClient ì²´í¬ ì œê±°)
      // if (abortedByClient) {
      //   console.log('ğŸ›‘ [onFinish] Client aborted; skipping final save');
      //   return;
      // }
      
      // v5 ìŠ¤íƒ€ì¼: ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ ì‹œ ëª¨ë“  ìƒˆ ë©”ì‹œì§€ë¥¼ ì €ì¥
      if (chatId && (user?.id || anonymousUserId) && completedMessages.length >= 1) {
        try {
          // ë§ˆì§€ë§‰ ìœ ì € ë©”ì‹œì§€ì™€ ìƒˆë¡œìš´ ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì°¾ê¸°
          const userMessages = completedMessages.filter(m => m.role === 'user');
          const assistantMessages = completedMessages.filter(m => m.role === 'assistant');
          
          const lastUserMessage = userMessages[userMessages.length - 1];
          const lastAssistantMessage = assistantMessages[assistantMessages.length - 1];
          
          if (lastUserMessage && lastAssistantMessage) {
            // ğŸš€ ë¶€ë¶„ ì €ì¥ í—ˆìš©: ë¹ˆ assistant ë©”ì‹œì§€ ì²´í¬ ì™„í™”
            const assistantContent = lastAssistantMessage.parts
              ?.filter((p: any) => p.type === 'text')
              ?.map((p: any) => p.text)
              ?.join('')?.trim() || '';
            
            // ë¶€ë¶„ ë‚´ìš©ì´ ìˆì–´ë„ ì €ì¥ í—ˆìš© (ì¤‘ë‹¨ëœ ì‘ë‹µë„ ì €ì¥)
            if (assistantContent === '' && !abortedByClient) {
              console.log('ğŸ›‘ [onFinish] Skipping save - assistant message is empty and not aborted');
              return;
            }

            // ì¤‘ë‹¨ëœ ì‘ë‹µì¸ ê²½ìš° ë¡œê·¸
            if (abortedByClient) {
              console.log('ğŸ›‘ [onFinish] Saving partial response (aborted)');
            }

            // ì›ë³¸ ì‚¬ìš©ì ë©”ì‹œì§€ ì°¾ê¸° (experimental_attachments í¬í•¨)
            const originalUserMessage = originalMessages.find((msg: any) => 
              msg.role === 'user' && 
              (msg.id === lastUserMessage.id || !lastUserMessage.id)
            ) || lastUserMessage;

            // ì¬ìƒì„± ì‹œ ê¸°ì¡´ ë©”ì‹œì§€ ID ì‚¬ìš©
            if (isRegeneration && existingMessageId) {
              lastAssistantMessage.id = existingMessageId;
              console.log('ğŸ”„ [onFinish] Using existing message ID for regeneration:', existingMessageId);
            }

            // ğŸš€ ì„¸ì…˜ upsert (ì•ˆì „í•˜ê²Œ)
            let finalChatId = chatId;
            let sessionExists = false;
            
            if (!isAnonymousUser) {
              try {
                // ë¨¼ì € ì„¸ì…˜ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                const { data: existingSession, error: checkError } = await supabase
                  .from('chat_sessions')
                  .select('id')
                  .eq('id', chatId)
                  .eq('user_id', user?.id || anonymousUserId)
                  .single();

                if (checkError || !existingSession) {
                  // ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                  // ğŸš€ ì´ˆê¸° ë©”ì‹œì§€ì—ì„œ ì œëª© ìƒì„± (ì‚¬ì´ë“œë°”ì™€ ë™ê¸°í™”)
                  const initialMessage = originalUserMessage.content || 
                    (originalUserMessage.parts
                      ?.filter((p: any) => p.type === 'text')
                      ?.map((p: any) => p.text)
                      ?.join(' ')) || '';
                  
                  const autoTitle = initialMessage.length > 30 
                    ? initialMessage.slice(0, 30) + '...' 
                    : initialMessage || 'New Chat';

                  const { data: newSession, error: createError } = await supabase
                    .from('chat_sessions')
                    .insert([{
                      id: chatId,
                      title: autoTitle, // ğŸš€ ìë™ ìƒì„±ëœ ì œëª© ì‚¬ìš©
                      current_model: model,
                      initial_message: initialMessage,
                      user_id: user?.id || anonymousUserId,
                    }])
                    .select()
                    .single();

                  if (createError) {
                    console.error('ğŸ’¥ [SESSION] Failed to create session:', createError);
                    // ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ ì‹œ ë©”ì‹œì§€ ì €ì¥ ê±´ë„ˆë›°ê¸°
                    return;
                  } else {
                    console.log('âœ… [SESSION] Session created successfully');
                    finalChatId = newSession.id;
                    sessionExists = true;
                    
                    // ğŸš€ ì œëª© ìƒì„± ì™„ì „ ì œê±° - ì‚¬ì´ë“œë°”ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬
                    // ë©”ì¸ API ì‘ë‹µ ì†ë„ ìµœëŒ€í™”
                  }
                } else {
                  // ì„¸ì…˜ì´ ì´ë¯¸ ì¡´ì¬í•¨
                  sessionExists = true;
                  console.log('âœ… [SESSION] Session already exists');
                }
              } catch (error) {
                console.error('ğŸ’¥ [SESSION] Session handling error:', error);
                // ì—ëŸ¬ ë°œìƒ ì‹œ ë©”ì‹œì§€ ì €ì¥ ê±´ë„ˆë›°ê¸°
                return;
              }
            }

            console.log('ğŸ’¾ [onFinish] Saving completed messages via v5 stream');
            
            // ğŸš€ ìµëª… ì‚¬ìš©ì ì§€ì›: ìµëª… ì‚¬ìš©ìëŠ” DB ì €ì¥ ê±´ë„ˆë›°ê¸°
            if (!isAnonymousUser && sessionExists) {
              await saveCompletedMessages(
                supabase,
                finalChatId,
                user?.id || anonymousUserId,
                originalUserMessage,
                lastAssistantMessage,
                model,
                getProviderFromModel(model),
                {
                  original_model: requestData.originalModel || model,
                  token_usage: (lastAssistantMessage as any).usage,
                  tool_results: globalCollectedToolResults || {}
                },
                isRegeneration || false
              );

              console.log('âœ… [onFinish] Messages saved successfully');
            } else if (isAnonymousUser) {
              console.log('ğŸš€ [ANONYMOUS] Skipping message save for anonymous user');
            } else {
              console.log('âš ï¸ [SESSION] Skipping message save - session not available');
            }

            // ğŸ†• Smart Memory Update for regular chat (ìµëª… ì‚¬ìš©ìëŠ” ê±´ë„ˆë›°ê¸°)
            if (chatId && !abortedByClient && !isAnonymousUser) {
              setTimeout(async () => {
                try {
                  // ì‚¬ìš©ì ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ
                  const userMessage = originalUserMessage.content || 
                    (originalUserMessage.parts
                      ?.filter((p: any) => p.type === 'text')
                      ?.map((p: any) => p.text)
                      ?.join(' ')) || '';
                  
                  // AI ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ
                  const aiMessage = lastAssistantMessage.parts
                    ?.filter((p: any) => p.type === 'text')
                    ?.map((p: any) => p.text)
                    ?.join('\n') || '';

                  if (userMessage && aiMessage) {
                    console.log('ğŸ§  [MEMORY] Starting smart memory update...');
                    
                    // ê¸°ì¡´ ë©”ëª¨ë¦¬ ë°ì´í„° ë¡œë“œ
                    const { data: memoryData } = await getAllMemoryBank(
                      supabase, 
                      user?.id || anonymousUserId
                    );
                    
                    await smartUpdateMemoryBanks(
                          supabase, 
                          user?.id || anonymousUserId, 
                          chatId, 
                          originalMessages, 
                          userMessage, 
                          aiMessage,
                          memoryData // ê¸°ì¡´ ë©”ëª¨ë¦¬ ë°ì´í„° ì „ë‹¬
                        );
                    console.log('âœ… [MEMORY] Smart memory update completed');
                  }
                } catch (error) {
                  console.error('ğŸ’¥ [MEMORY] Smart memory update failed:', error);
                }
              }, 1000);
            }
          }
        } catch (error) {
          console.error('ğŸ’¥ [onFinish] Error saving messages:', error);
        }
      }
    }
  });

  return createUIMessageStreamResponse({ stream });
}

import {
  streamText,
  createUIMessageStream,
  createUIMessageStreamResponse,
  generateObject,
  type ModelMessage,
  smoothStream,
  NoSuchToolError,
  generateId,
  stepCountIs,
} from 'ai';
import { createClient } from '@/utils/supabase/server';
import { providers } from '@/lib/providers';
import { getModelById, getModelByIdWithReasoningEffort, parseModelVariantId, resolveDefaultModelVariantId} from '@/lib/models/config';

import { 
  saveCompletedMessages,
  buildSystemPrompt,
  getCachedUserMemory,
  getFileEditToolIds
} from './services/chatService';
import {
  getProviderFromModel,
  extractTextFromMessage,
  processMessagesForAI,
  removeExtraContentFromMessages,
} from './utils/messageUtils';
import { refreshChatAttachmentUrlsInMessages } from './utils/refreshChatAttachmentUrls';
import { 
  TOOL_REGISTRY,
  getAvailableTools,
} from './utils/toolUtils';
import { handleRateLimiting, handleChatflixRateLimiting } from './utils/ratelimit';
import { checkSubscriptionFromDatabase } from '@/lib/subscription-db';
import { getProviderOptionsWithTools } from './utils/providerOptions';
import { processCompletionArtifacts } from './services/responsePostProcessor';

// ë©”ëª¨ë¦¬ ê´€ë ¨ import
import { smartUpdateMemoryBanks } from './services/memoryService';
import { selectOptimalModel } from './services/modelSelector';
import { estimateMultiModalTokens } from '@/utils/context-manager';
import { compressContextIfNeeded } from '@/utils/context-summarizer';
import { estimatePayloadBytes } from '@/app/utils/prepareMessagesForAPI';
import { stripHistoricalSearchFromMessages } from '@/utils/stripHistoricalSearch';
// import { markdownJoinerTransform } from './markdown-transform';

// Vercel Pro í”Œëœ + fluid compute: ìµœëŒ€ 800ì´ˆ (13ë¶„ 20ì´ˆ)ê¹Œì§€ ê°€ëŠ¥
export const maxDuration = 800;
export const dynamic = 'force-dynamic';
const MAX_PARSED_CHAT_REQUEST_BYTES = 12 * 1024 * 1024;

// ğŸš€ ìµëª… ì‚¬ìš©ììš© UUID ìƒì„± í•¨ìˆ˜
function generateAnonymousUserId(): string {
  // UUID v4 í˜•ì‹ìœ¼ë¡œ ìµëª… ì‚¬ìš©ì ID ìƒì„±
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
    const r = Math.random() * 16 | 0;
    const v = c === 'x' ? r : (r & 0x3 | 0x8);
    return v.toString(16);
  });
}

// Helper function to increment user daily request count
async function incrementSuccessfulRequestCount(
  supabaseClient: any,
  userId: string,
  requestDate: string,
  currentCount: number,
  isUserSubscribed: boolean
) {
  try {
    await supabaseClient
      .from('user_daily_requests')
      .upsert({
        user_id: userId,
        date: requestDate,
        count: currentCount + 1,
        last_request_at: new Date().toISOString(),
        is_subscribed: isUserSubscribed
      }, {
        onConflict: 'user_id,date' 
      });
  } catch (error) {
    // Error handling - request count update is non-critical
  }
}

function enforcePayloadBudget(
  messages: ModelMessage[],
  systemPrompt: string,
  modelId: string,
  maxBytes = 1_900_000,
): ModelMessage[] {
  const maxPromptTokens = (() => {
    const id = (modelId || '').toLowerCase();
    if (id.includes('claude') || id.includes('anthropic')) return 165_000;
    return 190_000;
  })();
  const buildPayload = (msgs: ModelMessage[]) => ({
    model: modelId,
    system: systemPrompt,
    messages: msgs,
  });
  const estimatePromptTokens = (msgs: ModelMessage[]) => {
    const systemTokens = Math.ceil((systemPrompt?.length || 0) / 4);
    const messageTokens = msgs.reduce((sum, msg) => {
      try {
        return sum + estimateMultiModalTokens(msg as any);
      } catch {
        return sum + 0;
      }
    }, 0);
    return systemTokens + messageTokens;
  };

  let trimmed = [...messages];
  let bytes = estimatePayloadBytes(buildPayload(trimmed));
  let tokens = estimatePromptTokens(trimmed);
  if (bytes <= maxBytes && tokens <= maxPromptTokens) return trimmed;

  // Prefer dropping oldest messages first while preserving the latest turn context.
  while (trimmed.length > 6 && (bytes > maxBytes || tokens > maxPromptTokens)) {
    trimmed = trimmed.slice(1);
    bytes = estimatePayloadBytes(buildPayload(trimmed));
    tokens = estimatePromptTokens(trimmed);
  }

  return trimmed;
}


export async function POST(req: Request): Promise<Response> {
  const supabase = await createClient();
  const { data: { user }, error: userError } = await supabase.auth.getUser();
  
  // ğŸš€ ìµëª… ì‚¬ìš©ì ì§€ì›: ë¡œê·¸ì¸í•˜ì§€ ì•Šì€ ì‚¬ìš©ìë„ ê¸°ë³¸ ì±„íŒ… ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥
  if (userError) {
    // AuthSessionMissingError(400)ì€ ìµëª… ì‹œ ì •ìƒ ë™ì‘ì´ë¯€ë¡œ ë¡œê¹…í•˜ì§€ ì•ŠìŒ
    const status = (userError as any)?.status;
    const errorMessage = (userError as any)?.message;
    
    // ê²ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œ ë°œìƒí•˜ëŠ” ì¼ë°˜ì ì¸ auth ì—ëŸ¬ë“¤ì€ ë¡œê¹…í•˜ì§€ ì•ŠìŒ
    if (status && status !== 400 && 
        !errorMessage?.includes('Auth session missing') &&
        !errorMessage?.includes('session not found')) {
      console.error('Auth error:', userError);
    }
    // ìµëª… ì‚¬ìš©ìë¡œ ì²˜ë¦¬ ê³„ì† ì§„í–‰
  }
  
  // ìµëª… ì‚¬ìš©ì í—¤ë” í™•ì¸
  const isAnonymousUser = !user;
  const anonymousUserId = req.headers.get('X-Anonymous-Id') || generateAnonymousUserId();

  const contentLengthHeader = req.headers.get('content-length');
  if (contentLengthHeader) {
    const contentLength = Number(contentLengthHeader);
    if (Number.isFinite(contentLength) && contentLength > MAX_PARSED_CHAT_REQUEST_BYTES) {
      return Response.json(
        {
          error: 'Request payload too large',
          detail: 'Please shorten the conversation or remove heavy tool outputs before retrying.',
        },
        { status: 413 },
      );
    }
  }

  let requestData: any;
  try {
    requestData = await req.json();
  } catch {
    return Response.json(
      {
        error: 'Invalid request body',
        detail: 'Request body was truncated or malformed. Please retry with a smaller conversation payload.',
      },
      { status: 413 },
    );
  }
  const parsedBodyBytes = estimatePayloadBytes(requestData);
  if (parsedBodyBytes > MAX_PARSED_CHAT_REQUEST_BYTES) {
    return Response.json(
      {
        error: 'Request payload too large',
        detail: 'Please shorten the conversation or remove heavy tool outputs before retrying.',
      },
      { status: 413 },
    );
  }
  
  // Track client aborts and wire to internal streams
  let abortedByClient = false;
  let internalAbortController: AbortController | null = null;
  try {
    // In Next.js/Fetch, Request has an AbortSignal
    const reqSignal: any = (req as any).signal;
    if (reqSignal && typeof reqSignal.addEventListener === 'function') {
      reqSignal.addEventListener('abort', () => {
        abortedByClient = true;
        try { internalAbortController?.abort(); } catch {}
      });
    }
  } catch {}
  let { messages, model, chatId, isRegeneration, existingMessageId, saveToDb = true, isAgentEnabled = false, selectedTool, experimental_attachments } = requestData;
  let resolvedModelVariant: string | undefined;

  const normalizeModelId = (modelId: string) => {
    resolvedModelVariant = modelId;
    const { baseId } = parseModelVariantId(modelId);
    return baseId;
  };

  model = normalizeModelId(model);
  
  // === CHAT ID VALIDATION ===
  // Trust the client-provided chatId - it's generated by nanoid on the client
  // This ensures client and server stay in sync for edit/regenerate operations
  if (!chatId || chatId.trim() === '') {
    return new Response('Invalid chatId', { status: 400 });
  }
  chatId = chatId.trim();
  
  // ğŸš€ ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬: ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ì— experimental_attachments ì¶”ê°€
  if (experimental_attachments && experimental_attachments.length > 0 && messages.length > 0) {
    const lastUserMessage = messages[messages.length - 1];
    if (lastUserMessage.role === 'user') {
      lastUserMessage.experimental_attachments = experimental_attachments;
    }
  }

  // ì›ë³¸ ë©”ì‹œì§€ ë°°ì—´ ë³´ì¡´ (ëª¨ë“  ìŠ¤ì½”í”„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
  const originalMessages = messages.slice();

  // Strip historical search outputs from the LLM context to avoid context_length_exceeded.
  // We keep the latest assistant+user turn intact (last user message plus its preceding assistant).
  messages = stripHistoricalSearchFromMessages(messages, {
    keepLastTurns: 1,
    leavePlaceholder: false,
    stripSearchPartsInKeptTurns: true,
  });

  // Map Chatflix Ultimate model to appropriate model based on agent mode
  if (model === 'chatflix-ultimate' || model === 'chatflix-ultimate-pro') {
      // Store the original model name for DB storage
      requestData.originalModel = model;
      
      try {
        const modelType = model as 'chatflix-ultimate' | 'chatflix-ultimate-pro';
        const { selectedModel } = await selectOptimalModel(messages, modelType);
        model = normalizeModelId(selectedModel);
        
        // ğŸ†• ì—ì´ì „íŠ¸ ëª¨ë“œì—ì„œë§Œ Kimi K2ë¥¼ gemini-2.5-flashë¡œ ëŒ€ì²´
        if (isAgentEnabled && model === 'accounts/fireworks/models/kimi-k2p5-none') {
          model = 'gemini-2.5-flash';
        }
      } catch (error) {
        const fallbackVariant = resolveDefaultModelVariantId('gemini-3-pro-preview');
        model = normalizeModelId(fallbackVariant);
      }
    }

  if (resolvedModelVariant) {
    requestData.resolvedModelVariant = resolvedModelVariant;
  }

  const executionModelId = resolvedModelVariant || model;

  // êµ¬ë… ìƒíƒœ í™•ì¸ (ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜) - ìµëª… ì‚¬ìš©ìëŠ” ë°”ë¡œ falseë¡œ ì²˜ë¦¬í•˜ì—¬ ë¶ˆí•„ìš”í•œ DB/Polar/Redis í˜¸ì¶œ ì œê±°
  const isSubscribed = isAnonymousUser
    ? false
    : await checkSubscriptionFromDatabase(user!.id);
  
  // Helper function to parse model ID and get model config
  const parseModelIdAndGetConfig = (modelId: string) => {
    const { baseId, reasoningEffort } = parseModelVariantId(modelId);
    if (reasoningEffort) {
      return getModelByIdWithReasoningEffort(baseId, reasoningEffort);
    }
    return getModelById(baseId);
  };
  
  // ì‚¬ìš©ìì˜ ì˜¤ëŠ˜ ìš”ì²­ íšŸìˆ˜ í™•ì¸
  const today = new Date().toISOString().split('T')[0]; // YYYY-MM-DD í˜•ì‹
  const { data: userRequests } = await supabase
    .from('user_daily_requests')
    .select('count')
    .eq('user_id', user?.id || anonymousUserId)
    .eq('date', today)
    .single();
  
  // í˜„ì¬ ìš”ì²­ íšŸìˆ˜ (ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì‹œì‘)
  const currentRequestCount = userRequests?.count || 0;

  // ğŸ†• Handle rate limiting based on model type
  const originalModel = requestData.originalModel;
  const isChatflixModel = originalModel === 'chatflix-ultimate' || originalModel === 'chatflix-ultimate-pro';
  
  if (isChatflixModel) {
    // Chatflix ëª¨ë¸ì€ ìì²´ rate limitë§Œ ì²´í¬ (ì„ íƒëœ ê°œë³„ ëª¨ë¸ rate limit ë¬´ì‹œ)
    const chatflixRateLimitResult = await handleChatflixRateLimiting(user?.id || anonymousUserId, originalModel, isSubscribed);
    if (!chatflixRateLimitResult.success) {
      const { error } = chatflixRateLimitResult;
      
      if (error) {
        return new Response(JSON.stringify({
          error: 'Too many requests',
          message: error.message,
          retryAfter: error.retryAfter,
          reset: new Date(error.reset).toISOString(),
          limit: error.limit,
          level: error.level,
          model: originalModel, // Use original Chatflix model name
          isSubscribed: isSubscribed // êµ¬ë… ìƒíƒœ í¬í•¨
        }), {
          status: 429,
          headers: {
            'Content-Type': 'application/json',
            'X-RateLimit-Limit': error.limit.toString(),
            'X-RateLimit-Remaining': '0',
            'X-RateLimit-Reset': new Date(error.reset).toISOString(),
          }
        });
      }
    }
  } else {
    // ì¼ë°˜ ëª¨ë¸ì€ ê¸°ì¡´ ë¡œì§ ì‚¬ìš© (ìµëª… ì‚¬ìš©ìë„ rate limit ì²´í¬ ì ìš©)
    // ğŸ”§ FIX: resolvedModelVariantë¥¼ ì‚¬ìš©í•˜ì—¬ variant IDë¡œ rate limit ì²´í¬
    // modelì€ ì´ë¯¸ normalizeModelIdë¡œ baseIdë¡œ ë³€í™˜ë˜ì—ˆìœ¼ë¯€ë¡œ, variant IDê°€ í•„ìš”í•¨
    const modelForRateLimit = resolvedModelVariant || requestData.model || model;
    const rateLimitResult = await handleRateLimiting(user?.id || anonymousUserId, modelForRateLimit, isSubscribed);
    if (!rateLimitResult.success) {
      const { error } = rateLimitResult;
      
      if (error) {
        return new Response(JSON.stringify({
          error: 'Too many requests',
          message: error.message,
          retryAfter: error.retryAfter,
          reset: new Date(error.reset).toISOString(),
          limit: error.limit,
          level: error.level,
          model: model,
          isSubscribed: isSubscribed // êµ¬ë… ìƒíƒœ í¬í•¨
        }), {
          status: 429,
          headers: {
            'Content-Type': 'application/json',
            'X-RateLimit-Limit': error.limit.toString(),
            'X-RateLimit-Remaining': '0',
            'X-RateLimit-Reset': new Date(error.reset).toISOString(),
          }
        });
      } else {
        // Fallback in case error is undefined
        return new Response(JSON.stringify({
          error: 'Too many requests',
          message: 'Rate limit exceeded',
          isSubscribed: isSubscribed // êµ¬ë… ìƒíƒœ í¬í•¨
        }), {
          status: 429,
          headers: {
            'Content-Type': 'application/json'
          }
        });
      }
    }
  }

  let globalCollectedToolResults: any = {}; // Store tool results globally
  
  const stream = createUIMessageStream({
    // Preserve full originals for persistence/memory bookkeeping.
    originalMessages,
    execute: async ({ writer }): Promise<void> => {
        // ğŸš€ AI ì‘ë‹µ ì¦‰ì‹œ ì‹œì‘ (ì„¸ì…˜ ì²˜ë¦¬ì™€ ì™„ì „ ë¶„ë¦¬)
        const processMessages = [...messages];

        // ğŸš€ ì„œë²„-ì¸¡ ID ìƒì„±: ê¸°ë³¸ì€ ì„œë²„ì—ì„œ ìƒì„±, ì¬ìƒì„±ë§Œ ê¸°ì¡´ ID ìœ ì§€
        let assistantMessageId: string;
        if (isRegeneration && existingMessageId) {
          // ì¬ìƒì„±: ê¸°ì¡´ ë©”ì‹œì§€ ID ìœ ì§€ (ë®ì–´ì“°ê¸°)
          assistantMessageId = existingMessageId;
        } else {
          // ìƒˆ ë©”ì‹œì§€/í¸ì§‘ í›„ ì „ì†¡: ì„œë²„ì—ì„œ ìƒˆë¡œ ìƒì„±
          assistantMessageId = generateId();
        }

        // ğŸš€ ì„œë²„-ì¸¡ IDë¥¼ ìŠ¤íŠ¸ë¦¼ start ì´ë²¤íŠ¸ì—ì„œ ì¦‰ì‹œ ì „ì†¡
        writer.write({
          type: 'start',
          messageId: assistantMessageId,
        });

        // Expose for onError/onFinish handlers
        // assistantMessageIdGlobal = assistantMessageId;

        const abortController = new AbortController();
        // expose the internal controller for client abort wiring
        internalAbortController = abortController;

        // Track aborts so downstream save logic can allow partial storage when needed
        abortController.signal.addEventListener('abort', () => {
          abortedByClient = true;
        });

        // Get model config using the helper function
        const modelConfig = parseModelIdAndGetConfig(executionModelId);

        // 3. í–¥ìƒëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìºì‹œëœ ë©”ëª¨ë¦¬ ì‚¬ìš©) - ì—ëŸ¬ ì‹œì—ë„ ê³„ì† ì§„í–‰
        // ğŸš€ ìµœì í™”: í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì „ë‹¬ëœ ë©”ëª¨ë¦¬ë¥¼ ìš°ì„  ì‚¬ìš© (localStorage ìºì‹œ í™œìš©)
        let userMemory = requestData.userMemory || null;
        
        // í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë©”ëª¨ë¦¬ë¥¼ ì „ë‹¬í•˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì„œë²„ì—ì„œ ë¡œë“œ
        if (!userMemory && !isAnonymousUser) {
          userMemory = await getCachedUserMemory(user?.id || anonymousUserId);
        }
        
        // ğŸ”§ MEDIUM PRIORITY OPTIMIZATION: ë©”ì‹œì§€ë³„ í† í° ë¯¸ë¦¬ ê³„ì‚° ë° ìºì‹±
        const messagesWithTokens = processMessages.map(msg => {
          const tokenCount = estimateMultiModalTokens(msg as any);
          return {
            ...msg,
            _tokenCount: tokenCount
          };
        });
        
        if (isAgentEnabled) {
          const optimizedMessagesForRouting = messagesWithTokens;

          // í˜„ì¬ ì§ˆë¬¸ ì¶”ì¶œì„ ìœ„í•œ ì¤€ë¹„
          let userQuery = '';
          
          // í˜„ì¬ ì§ˆë¬¸ë§Œ userQueryì— í• ë‹¹
          const currentMessage = optimizedMessagesForRouting[optimizedMessagesForRouting.length - 1];
          userQuery = extractTextFromMessage(currentMessage);

          // ğŸ†• ì‚¬ìš©ìê°€ ì§ì ‘ ë„êµ¬ë¥¼ ì„ íƒí•œ ê²½ìš° vs ìë™ ë¼ìš°íŒ…
          let selectedActiveTools: Array<keyof typeof TOOL_REGISTRY>;
          
          
          if (selectedTool && selectedTool !== 'file_upload') {
            // ì‚¬ìš©ìê°€ ì§ì ‘ ë„êµ¬ë¥¼ ì„ íƒí•œ ê²½ìš°
            // ì›¹ì„œì¹˜ í† í”½ì¸ ê²½ìš° ì²˜ë¦¬
            if (selectedTool.startsWith('web_search:')) {
              const topic = selectedTool.split(':')[1];
              
              // ì›¹ì„œì¹˜ ë„êµ¬ì— íŠ¹ì • í† í”½ì„ ê°•ì œë¡œ ì„¤ì •
              selectedActiveTools = ['web_search'] as Array<keyof typeof TOOL_REGISTRY>;
              
              // ì›¹ì„œì¹˜ ë„êµ¬ ìƒì„± ì‹œ ì‚¬ìš©í•  í† í”½ ì •ë³´ë¥¼ ì €ì¥
              (writer as any)._selectedWebSearchTopic = topic;
            } else if (selectedTool === 'google-images') {
              // Google Images ë„êµ¬ ì„ íƒ ì‹œ ì²˜ë¦¬
              // Google Search ë„êµ¬ì— google_images ì—”ì§„ì„ ê°•ì œë¡œ ì„¤ì •
              selectedActiveTools = ['google_search'] as Array<keyof typeof TOOL_REGISTRY>;
              
              // Google Search ë„êµ¬ ìƒì„± ì‹œ ì‚¬ìš©í•  ì—”ì§„ ì •ë³´ë¥¼ ì €ì¥
              (writer as any)._selectedGoogleSearchEngine = 'google_images';
            } else if (selectedTool === 'google-videos') {
              // Google Videos ë„êµ¬ ì„ íƒ ì‹œ ì²˜ë¦¬
              // Google Search ë„êµ¬ì— google_videos ì—”ì§„ì„ ê°•ì œë¡œ ì„¤ì •
              selectedActiveTools = ['google_search'] as Array<keyof typeof TOOL_REGISTRY>;
              
              // Google Search ë„êµ¬ ìƒì„± ì‹œ ì‚¬ìš©í•  ì—”ì§„ ì •ë³´ë¥¼ ì €ì¥
              (writer as any)._selectedGoogleSearchEngine = 'google_videos';
            } else if (selectedTool === 'wan25_text_to_video') {
              // Wan 2.5 Text to Video ì„ íƒ ì‹œ ì²˜ë¦¬
              selectedActiveTools = ['wan25_video'] as Array<keyof typeof TOOL_REGISTRY>;
              (writer as any)._selectedWan25VideoModel = 'text-to-video';
            } else if (selectedTool === 'wan25_image_to_video') {
              // Wan 2.5 Image to Video ì„ íƒ ì‹œ ì²˜ë¦¬
              selectedActiveTools = ['wan25_video'] as Array<keyof typeof TOOL_REGISTRY>;
              (writer as any)._selectedWan25VideoModel = 'image-to-video';
            } else if (selectedTool === 'grok_text_to_video') {
              selectedActiveTools = ['grok_video'] as Array<keyof typeof TOOL_REGISTRY>;
              (writer as any)._selectedGrokVideoModel = 'text-to-video';
            } else if (selectedTool === 'grok_image_to_video') {
              selectedActiveTools = ['grok_video'] as Array<keyof typeof TOOL_REGISTRY>;
              (writer as any)._selectedGrokVideoModel = 'image-to-video';
            } else if (selectedTool === 'grok_video_edit') {
              selectedActiveTools = ['grok_video'] as Array<keyof typeof TOOL_REGISTRY>;
              (writer as any)._selectedGrokVideoModel = 'video-edit';
            } else if (selectedTool === 'video_upscaler') {
              selectedActiveTools = ['video_upscaler'] as Array<keyof typeof TOOL_REGISTRY>;
            } else if (selectedTool === 'image_upscaler') {
              selectedActiveTools = ['image_upscaler'] as Array<keyof typeof TOOL_REGISTRY>;
            } else if (selectedTool === 'workspace') {
              selectedActiveTools = getFileEditToolIds() as Array<keyof typeof TOOL_REGISTRY>;
            } else if (selectedTool === 'browser_observe') {
              selectedActiveTools = ['browser_observe', 'run_python_code', 'gemini_image_tool'] as Array<keyof typeof TOOL_REGISTRY>;
            } else {
              // ì¼ë°˜ ë„êµ¬ì¸ ê²½ìš°
              selectedActiveTools = [selectedTool] as Array<keyof typeof TOOL_REGISTRY>;
            }
          } else {
            // ğŸš€ ëª¨ë“  ë„êµ¬ í—ˆìš© (ë¼ìš°íŒ… ë¶„ì„ ìƒëµ)
            const allAvailableTools = getAvailableTools();
            selectedActiveTools = allAvailableTools as Array<keyof typeof TOOL_REGISTRY>;
            
            // ğŸ”§ ê¸°ì¡´ ë¼ìš°íŒ… ë¶„ì„ ì½”ë“œ (ì£¼ì„ ì²˜ë¦¬ - í•„ìš”ì‹œ ë³µì› ê°€ëŠ¥)
            /*
            // ìë™ ë¼ìš°íŒ… ì‚¬ìš©
            const baseAvailableToolsList = getAvailableTools();
            const analysisModel = 'gemini-2.5-flash-lite';
            const toolDescriptions = getToolDescriptions();

            // ğŸš€ V6 Plan: New unified analysis and routing
            // ğŸ”§ FIX: Use unified converter for analysis
            const messagesForAnalysis = convertToModelMessages(messagesWithTokens);

            const routeAnalysisResult = await analyzeRequestAndDetermineRoute(
              analysisModel,
              model,
              baseAvailableToolsList,
              messagesForAnalysis, // Use converted messages for routing analysis
              toolDescriptions
            );
            
            const routingDecision = routeAnalysisResult.object;
            selectedActiveTools = addToolsWithPreviousResults(routingDecision.tools);
            */
          }
              
          // Provider options with tools
          const providerOptions = getProviderOptionsWithTools(
            executionModelId,
            modelConfig,
            user?.id || anonymousUserId,
            selectedActiveTools.length > 0,
            chatId
          );

          // RESPOND: ë„êµ¬ ì‹¤í–‰ ëª¨ë¸ ê²°ì •
          let toolExecutionModel = executionModelId;
          const maxAgentSteps = selectedActiveTools.length > 0 ? 30 : 3;

          // ğŸ†• AI SDK v5: ì „ì²´ ë„êµ¬ ì„¸íŠ¸ ì •ì˜ + í™œì„± ë„êµ¬ ì œí•œ
          // ğŸ”¥ chatId ì¶”ê°€: ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ë„êµ¬ì—ì„œ DBì—ì„œ ì „ì²´ ë©”ì‹œì§€ ê°€ì ¸ì™€ imageMap êµ¬ì¶• (ê°€ìƒí™” ë¬¸ì œ í•´ê²°)
          const allTools = Object.fromEntries(
            Object.entries(TOOL_REGISTRY).map(([toolName, config]) => [
              toolName,
              toolName === 'web_search' && (writer as any)._selectedWebSearchTopic
                ? (config.createFn as any)(writer, (writer as any)._selectedWebSearchTopic) // ì›¹ì„œì¹˜ì— ê°•ì œ í† í”½ ì „ë‹¬
                : toolName === 'google_search' && (writer as any)._selectedGoogleSearchEngine
                ? (config.createFn as any)(writer, (writer as any)._selectedGoogleSearchEngine) // Google Searchì— ê°•ì œ ì—”ì§„ ì „ë‹¬
                : toolName === 'gemini_image_tool'
                ? (config.createFn as any)(writer, user?.id || anonymousUserId, messagesWithTokens, chatId) // chatId ì¶”ê°€
                : toolName === 'seedream_image_tool'
                ? (config.createFn as any)(writer, user?.id || anonymousUserId, messagesWithTokens, chatId) // chatId ì¶”ê°€
                // : toolName === 'qwen_image_edit'
                // ? (config.createFn as any)(writer, user?.id || anonymousUserId, messagesWithTokens, chatId) // chatId ì¶”ê°€
                : toolName === 'wan25_video'
                ? (config.createFn as any)(writer, user?.id || anonymousUserId, messagesWithTokens, chatId, (writer as any)._selectedWan25VideoModel) // forcedModel ì „ë‹¬
                : toolName === 'grok_video'
                ? (config.createFn as any)(writer, user?.id || anonymousUserId, messagesWithTokens, chatId, (writer as any)._selectedGrokVideoModel) // forcedModel ì „ë‹¬
                : toolName === 'video_upscaler'
                ? (config.createFn as any)(writer, user?.id || anonymousUserId, messagesWithTokens, chatId)
                : toolName === 'image_upscaler'
                ? (config.createFn as any)(writer, user?.id || anonymousUserId, messagesWithTokens, chatId)
                : ['db_search_tool_results', 'db_read_tool_result_window'].includes(toolName)
                ? (config.createFn as any)(writer, chatId, user?.id || anonymousUserId, supabase)
                : [...getFileEditToolIds(), 'run_python_code', 'browser_observe'].includes(toolName)
                ? (config.createFn as any)(writer, chatId, supabase) // file-edit / code run: sandbox per chat
                : (config.createFn as any)(writer)
            ])
          );
          
          // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì • (ìºì‹œëœ ë©”ëª¨ë¦¬ ì‚¬ìš©)
          const agentSystemPrompt = buildSystemPrompt(
            'agent', 
            userMemory,
            {
              selectedTools: selectedActiveTools,
              forcedWebSearchTopic: (writer as any)._selectedWebSearchTopic,
              isAnonymousUser,
              isSubscribed
            }
          );

          // ğŸ†• STEP 2: Prepare optimized messages for final execution
          // ğŸ”§ Context compression: Summarize if exceeding 80% of context window
          const { finalMessages: compressedMessages } = await compressContextIfNeeded(
            messagesWithTokens,
            agentSystemPrompt,
            executionModelId,
            supabase,
            chatId,
            isAnonymousUser
          );
          
          // chat_attachments signed URL ê°±ì‹  (AI SDK ë‹¤ìš´ë¡œë“œ ì‹œ 400 InvalidJWT ë°©ì§€)
          const messagesWithFreshUrls = await refreshChatAttachmentUrlsInMessages(compressedMessages);
          // íŒŒì¼ í¸ì§‘/ì½”ë“œ ì‹¤í–‰ ë„êµ¬ ì‚¬ìš© ì‹œ: ì‚¬ìš©ì ì²¨ë¶€ íŒŒì¼ì„ ìƒŒë“œë°•ìŠ¤ì— ì—…ë¡œë“œí•˜ê³  ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê²½ë¡œ ì¶”ì 
          const fileAndCodeToolIds = [...getFileEditToolIds(), 'run_python_code', 'browser_observe'];
          const hasFileEditTools = selectedActiveTools.some((t: string) => fileAndCodeToolIds.includes(t));
          let messagesForProcess = messagesWithFreshUrls;
          if (hasFileEditTools && messagesWithFreshUrls.length > 0) {
            const { uploadMessageAttachmentsToSandbox, getWorkspaceContextText, workspacePathForFilename } = await import('./lib/sandboxService');
            // Upload attachments from ALL user messages (not just last) so that
            // files from earlier messages are restored when the sandbox has expired.
            const userMessages = messagesWithFreshUrls.filter((m: any) => m.role === 'user');
            for (const userMsg of userMessages) {
              await uploadMessageAttachmentsToSandbox(chatId, userMsg, supabase);
            }
            messagesForProcess = messagesWithFreshUrls.map((m: any) => ({ ...m, parts: Array.isArray(m.parts) ? [...m.parts] : m.parts }));
            const isTextOrCodePart = (part: { type?: string; mediaType?: string; filename?: string }) => {
              if (part.type !== 'file') return false;
              const ct = (part.mediaType || '').toLowerCase();
              const name = part.filename || '';
              if (ct.startsWith('image/') || ct === 'application/pdf') return false;
              const codeExt = /\.(js|ts|jsx|tsx|py|java|c|cpp|cs|go|rb|php|html|css|sql|scala|swift|kt|rs|dart|json|xml|yaml|yml|md|txt|csv)$/i;
              return !!name.match(codeExt) || ct.includes('text/') || ct.includes('javascript') || ct.includes('json');
            };
            // Replace file attachment parts with workspace path hints in ALL user messages
            let lastUserMsgIdx = -1;
            for (let i = 0; i < messagesForProcess.length; i++) {
              const msg = messagesForProcess[i];
              if (msg.role === 'user' && msg.parts && Array.isArray(msg.parts)) {
                lastUserMsgIdx = i;
                msg.parts = msg.parts.map((part: any) => {
                  if (isTextOrCodePart(part)) {
                    const path = workspacePathForFilename(part.filename || 'file');
                    return { type: 'text', text: `Attached file in workspace: ${path}. Use read_file("${path}") to read content.` };
                  }
                  return part;
                });
              }
            }
            const workspaceText = await getWorkspaceContextText(chatId, supabase);
            if (workspaceText && lastUserMsgIdx >= 0 && messagesForProcess[lastUserMsgIdx].parts) {
              messagesForProcess[lastUserMsgIdx].parts.push({ type: 'text', text: workspaceText });
            }
          }
          // ğŸ”§ AI SDK v5: ê³µí†µ ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜ ì‚¬ìš© (ë„êµ¬ ìœ ë¬´ì™€ ê´€ê³„ì—†ì´ ë™ì¼)
          const finalMessagesForExecution = await processMessagesForAI(messagesForProcess, executionModelId);
          
          // ğŸ”¥ Fireworks API í˜¸í™˜ì„±: extra_content ì œê±° (API í˜¸ì¶œ ì§ì „ ìµœì¢… ì •ë¦¬)
          const cleanedMessages = removeExtraContentFromMessages(finalMessagesForExecution, executionModelId);
          const budgetedMessages = enforcePayloadBudget(cleanedMessages, agentSystemPrompt, toolExecutionModel);

          // system prompt ë¡œê·¸
          // console.log('[API Request - Agent Mode] System prompt:', agentSystemPrompt);

          // ğŸ” DEBUG: ìµœì¢… ì „ë‹¬ ë©”ì‹œì§€ ë¡œê·¸
          console.log('[API Request - Agent Mode] Final messages being sent to AI:', {
            chatId,
            messageCount: finalMessagesForExecution.length,
            compressedCount: compressedMessages.length,
            messages: finalMessagesForExecution.map((m: any, idx: number) => {
              let fullTextContent = '';
              if (Array.isArray(m.parts)) {
                fullTextContent = m.parts
                  .filter((p: any) => p.type === 'text' && p.text)
                  .map((p: any) => p.text)
                  .join(' ');
              } else if (Array.isArray(m.content)) {
                fullTextContent = m.content
                  .filter((p: any) => p.type === 'text' && p.text)
                  .map((p: any) => p.text)
                  .join(' ');
              } else if (typeof m.content === 'string') {
                fullTextContent = m.content;
              }
              const isSummary = fullTextContent.includes('[Previous Conversation Summary]');
              // ìš”ì•½ ë©”ì‹œì§€ëŠ” ì „ì²´ ë‚´ìš© ì¶œë ¥, ê·¸ ì™¸ëŠ” 300ìë§Œ
              const displayContent = isSummary 
                ? fullTextContent 
                : (fullTextContent.slice(0, 300) + (fullTextContent.length > 300 ? '...' : ''));
              return {
                index: idx,
                role: m.role,
                isSummary,
                content: displayContent || `[no text - content type: ${Array.isArray(m.content) ? 'array' : typeof m.content}]`,
                contentLength: fullTextContent.length,
                partsCount: Array.isArray(m.parts) ? m.parts.length : 0
              };
            })
          });

          // console.log('agentSystemPrompt', agentSystemPrompt);
          
          // ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš° í…ìŠ¤íŠ¸ ì‘ë‹µì„ ì¡°ê±´ë¶€ë¡œ ì²˜ë¦¬
          const textResponsePromise = streamText({
            model: providers.languageModel(toolExecutionModel),
            experimental_transform: [
              smoothStream({delayInMs: 25}),
              // markdownJoinerTransform(),
            ],
            system: agentSystemPrompt,
            messages: budgetedMessages,
            tools: allTools,
            activeTools: selectedActiveTools,
            providerOptions,
            stopWhen: stepCountIs(maxAgentSteps),
            toolChoice: 'auto',
            maxRetries: 20,
            abortSignal: abortController.signal,
            experimental_repairToolCall: async ({ toolCall, tools, inputSchema, error }) => {
              if (NoSuchToolError.isInstance(error)) {
                return null; // do not attempt to fix invalid tool names
              }

              const tool = tools[toolCall.toolName as keyof typeof tools];

              // Pre-process the input to handle JSON string cases
              let processedInput = toolCall.input;
              if (typeof toolCall.input === 'string') {
                try {
                  processedInput = JSON.parse(toolCall.input);
                } catch {
                  // If it's not valid JSON, keep as is
                }
              }

              const { object: repairedArgs } = await generateObject({
                model: providers.languageModel('accounts/fireworks/models/kimi-k2p5'),
                schema: tool.inputSchema,
                prompt: [
                  `The model tried to call the tool "${toolCall.toolName}" with the following arguments:`,
                  JSON.stringify(processedInput),
                  `The tool accepts the following schema:`,
                  JSON.stringify(inputSchema(toolCall)),
                  'Please fix the arguments to match the schema exactly.',
                  'Ensure all required fields are provided and data types are correct.',
                  'If you see JSON strings that should be arrays, parse them properly.',
                  `Today's date is ${new Date().toLocaleDateString('en-US', {
                    year: 'numeric',
                    month: 'long',
                    day: 'numeric',
                  })}`,
                ].join('\n'),
              });

              return { ...toolCall, args: JSON.stringify(repairedArgs) };
            },
            onChunk: process.env.NODE_ENV === 'development' ? (event) => {
              const { chunk } = event;
              if (chunk?.type === 'tool-call' || chunk?.type === 'tool-result') {
                // ê°œë°œ í™˜ê²½ì—ì„œë§Œ ë„êµ¬ í˜¸ì¶œ ë¡œê¹…
              }
            } : undefined,
            onFinish: async (completion) => {
              if (abortController.signal.aborted) return;
              
              // ğŸš€ ìµœì í™”: ìš”ì²­ ì¹´ìš´íŠ¸ ì¦ê°€ë¥¼ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ (ì‚¬ìš©ì ì‘ë‹µ ë¸”ë¡œí‚¹ ë°©ì§€)
              incrementSuccessfulRequestCount(supabase, user?.id || anonymousUserId, today, currentRequestCount, isSubscribed)
                .catch(error => console.error('Failed to increment request count:', error));
             
              const { collectedToolResults } = await processCompletionArtifacts({
                writer,
                assistantMessageId,
                userQuery,
                completion,
                userMemory,
                isAnonymousUser,
                allTools,
                selectedActiveTools,
              });

              globalCollectedToolResults = { ...collectedToolResults };
            }
          });

          // textResponsePromise.consumeStream(); // ğŸš€ AI SDK v5: toUIMessageStream internally handles consumption
          writer.merge(textResponsePromise.toUIMessageStream({
            sendReasoning: true,
            sendStart: false, // ğŸš€ ì„œë²„-ì¸¡ ID ì‚¬ìš©ì„ ìœ„í•´ ìì²´ start ì´ë²¤íŠ¸ ë¹„í™œì„±í™”
          }));
        } else {
          // ì¼ë°˜ ì±„íŒ… íë¦„ - ì›ë˜ ì½”ë“œ ì‚¬ìš©ì— í† í° ì œí•œ ìµœì í™” ì¶”ê°€
          //  ì´ë¯¸ ê³„ì‚°ëœ ì‹œìŠ¤í…œ í† í° ì¬ì‚¬ìš©

          // Get provider options for regular (non-agent) mode
          const regularProviderOptions = getProviderOptionsWithTools(
            executionModelId,
            modelConfig,
            user?.id || anonymousUserId,
            false, // No tools in regular mode
            chatId
          );
          
          const regularSystemPrompt = buildSystemPrompt('regular', userMemory, {
            isAnonymousUser,
            isSubscribed
          });

          // ğŸ”§ Context compression: Summarize if exceeding 80% of context window
          const { finalMessages: compressedMessages } = await compressContextIfNeeded(
            messagesWithTokens,
            regularSystemPrompt,
            executionModelId,
            supabase,
            chatId,
            isAnonymousUser
          );
          
          // chat_attachments signed URL ê°±ì‹  (AI SDK ë‹¤ìš´ë¡œë“œ ì‹œ 400 InvalidJWT ë°©ì§€)
          const messagesWithFreshUrls = await refreshChatAttachmentUrlsInMessages(compressedMessages);
          // ğŸ”§ AI SDK v5: ê³µí†µ ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜ ì‚¬ìš©
          const messages: ModelMessage[] = await processMessagesForAI(messagesWithFreshUrls, executionModelId);
          
          // ğŸ”¥ Fireworks API í˜¸í™˜ì„±: extra_content ì œê±° (API í˜¸ì¶œ ì§ì „ ìµœì¢… ì •ë¦¬)
          const cleanedMessages = removeExtraContentFromMessages(messages, executionModelId);
          const budgetedMessages = enforcePayloadBudget(cleanedMessages, regularSystemPrompt, executionModelId);
          
          // ğŸ” DEBUG: ìµœì¢… ì „ë‹¬ ë©”ì‹œì§€ ë¡œê·¸
          // console.log('[API Request - Regular Mode] Final messages being sent to AI:', {
          //   chatId,
          //   messageCount: messages.length,
          //   compressedCount: compressedMessages.length,
          //   messages: messages.map((m: any, idx: number) => {
          //     let fullTextContent = '';
          //     if (Array.isArray(m.parts)) {
          //       fullTextContent = m.parts
          //         .filter((p: any) => p.type === 'text' && p.text)
          //         .map((p: any) => p.text)
          //         .join(' ');
          //     } else if (Array.isArray(m.content)) {
          //       fullTextContent = m.content
          //         .filter((p: any) => p.type === 'text' && p.text)
          //         .map((p: any) => p.text)
          //         .join(' ');
          //     } else if (typeof m.content === 'string') {
          //       fullTextContent = m.content;
          //     }
          //     const isSummary = fullTextContent.includes('[Previous Conversation Summary]');
          //     // ìš”ì•½ ë©”ì‹œì§€ëŠ” ì „ì²´ ë‚´ìš© ì¶œë ¥, ê·¸ ì™¸ëŠ” 300ìë§Œ
          //     const displayContent = isSummary 
          //       ? fullTextContent 
          //       : (fullTextContent.slice(0, 300) + (fullTextContent.length > 300 ? '...' : ''));
          //     return {
          //       index: idx,
          //       role: m.role,
          //       isSummary,
          //       content: displayContent || `[no text - content type: ${Array.isArray(m.content) ? 'array' : typeof m.content}]`,
          //       contentLength: fullTextContent.length,
          //       partsCount: Array.isArray(m.parts) ? m.parts.length : 0
          //     };
          //   })
          // });
          
          const result = streamText({
            model: providers.languageModel(executionModelId),
            experimental_transform: [
              smoothStream({delayInMs: 25}),
              // markdownJoinerTransform(),
            ],
            system: regularSystemPrompt,
            messages: budgetedMessages,
            providerOptions: regularProviderOptions,
            stopWhen: stepCountIs(3),
            maxRetries: 20,
            abortSignal: abortController.signal,
            onFinish: async (completion) => {
              if (abortController.signal.aborted) return;

              // ğŸš€ ìµœì í™”: ìš”ì²­ ì¹´ìš´íŠ¸ ì¦ê°€ë¥¼ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ (ì‚¬ìš©ì ì‘ë‹µ ë¸”ë¡œí‚¹ ë°©ì§€)
              if (!abortController.signal.aborted && !isAnonymousUser) {
                incrementSuccessfulRequestCount(
                  supabase,
                  user?.id || anonymousUserId,
                  today,
                  currentRequestCount,
                  isSubscribed
                ).catch(error => console.error('Failed to increment request count:', error));
              }

              // ğŸš€ ì¼ë°˜ ëª¨ë“œì—ì„œëŠ” follow-up question ì œê±° (ì„±ëŠ¥ ìµœì í™”)
              
              // ğŸš€ ìµœì í™”: í† í° ì‚¬ìš©ëŸ‰ ì €ì¥ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ (ì‚¬ìš©ì ì‘ë‹µ ë¸”ë¡œí‚¹ ë°©ì§€)
              setTimeout(() => {
                try {
                  globalCollectedToolResults.token_usage = {
                    totalUsage: completion.totalUsage || null
                  };
                } catch (error) {
                  console.error('Failed to save token usage:', error);
                }
              }, 0);
            }
          });
          writer.merge(result.toUIMessageStream({
            sendReasoning: true,
            sendStart: false, // ğŸš€ ì„œë²„-ì¸¡ ID ì‚¬ìš©ì„ ìœ„í•´ ìì²´ start ì´ë²¤íŠ¸ ë¹„í™œì„±í™”
          }));
    }
    },
    onError: (error) => {
      return 'Oops, an error occurred!';
    },
    onFinish: async ({ messages: completedMessages }) => {
      // Skip for anonymous users
      if (isAnonymousUser) {
        return;
      }
      if (abortedByClient) return;

      if (!chatId || !user?.id) {
        return;
      }

      // Get last messages
      const userMessages = completedMessages.filter(m => m.role === 'user');
      const assistantMessages = completedMessages.filter(m => m.role === 'assistant');
      
      const lastUserMessage = userMessages[userMessages.length - 1];
      const lastAssistantMessage = assistantMessages[assistantMessages.length - 1];
      
      if (!lastUserMessage || !lastAssistantMessage) {
        return;
      }

      // Validate assistant has content
      const assistantContent = lastAssistantMessage.parts
        ?.filter((p: any) => p.type === 'text')
        ?.map((p: any) => p.text)
        ?.join('')?.trim() || '';
      
      if (!assistantContent) {
        return;
      }

      // Find original user message with attachments
      const originalUserMessage = originalMessages.find((msg: any) => 
        msg.role === 'user' && (msg.id === lastUserMessage.id || !lastUserMessage.id)
      ) || lastUserMessage;

      // Handle regeneration
      if (isRegeneration && existingMessageId) {
        lastAssistantMessage.id = existingMessageId;
      }

      // === SAVE MESSAGES (synchronous with retry) ===
      try {
        await saveCompletedMessages(
          supabase,
          chatId,
          user.id,
          originalUserMessage,
          lastAssistantMessage,
          executionModelId,
          getProviderFromModel(executionModelId),
          {
            original_model: requestData.originalModel || model,
            token_usage: globalCollectedToolResults.token_usage || null,
            tool_results: globalCollectedToolResults || {},
            parts: lastAssistantMessage.parts || null
          },
          isRegeneration || false
        );
      } catch (error) {
        // Message is in user's local state, will persist on next interaction
      }

      // === MEMORY UPDATE (background - not critical) ===
      if (!abortedByClient) {
        setImmediate(async () => {
          try {
            const userMsg = originalUserMessage.content || 
              (originalUserMessage.parts?.filter((p: any) => p.type === 'text')?.map((p: any) => p.text)?.join(' ')) || '';
            const aiMsg = assistantContent;
            
            if (userMsg && aiMsg) {
              await smartUpdateMemoryBanks(supabase, user.id, chatId, originalMessages, userMsg, aiMsg);
            }
          } catch (error) {
            // Memory update failed - non-critical
          }
        });
      }
    }
  });

  return createUIMessageStreamResponse({ stream });
}
